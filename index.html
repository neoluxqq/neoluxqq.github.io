<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Qingqin LIU </title> <meta name="author" content="Qingqin LIU"> <meta name="description" content="Personal Website of Qingqin " neo liu> <meta name="keywords" content="Human-Computer Interaction, VR/AR, Haptics, Creative Experience"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/Neo.jpeg?2199e93d14f7908ecf7cd7fd1e7555cb"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://neoluxqq.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> Qingqin LIU </h1> <p class="desc">⚛️🔭🌌📡🛸🤖🖥👀👋🧠🤯 <a href="https://meilab-hk.github.io/index.html" rel="external nofollow noopener" target="_blank">MEI LAB</a>. Kowloon. Hong Kong.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/prof_pic.jpg?6182242d815a95de525dd99fd1a02fbd" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="prof_pic.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p>(photo by <a href="http://home.ustc.edu.cn/~wynnewang/" rel="external nofollow noopener" target="_blank">Wynne</a>)</p> <p>neoliu-c@my.cityu.edu.hk</p> </div> </div> <div class="clearfix"> <p>Hi! I am Qingqin Liu (刘晴钦 in Chinese). I am a PhD student of the <a href="https://meilab-hk.github.io/index.html" rel="external nofollow noopener" target="_blank">MEI Lab</a> at City University of Hong Kong, advised by <a href="https://zhukening.wixsite.com/aboutme" rel="external nofollow noopener" target="_blank">Prof. Kening Zhu</a>. I received my Master’s degree in Communication from the University of Science and Technology of China (USTC), advised by <a href="https://dblp.org/pid/117/0075-1.html" rel="external nofollow noopener" target="_blank">Prof. Yanxiang Zhang</a>. Prior to that, I completed a Bachelor of Science in Astronomy at USTC 🌌</p> <p>I am interested in enabling human-computer interactions using different modalities(touch, gestures, haptics, gaze, etc.), and on different devices (hand-held, head-mounted, in midair, esp. VR/AR/MR). Also, I am interested in game interaction and playable interfaces, game design and development, and player experience evaluation.</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 02, 2025</th> <td> <a href="https://neoluxqq.github.io/">VirCHEW Reality🍡</a> was conditionally accepted by <span style="color: #4DAAA6;">SIGGRAPH25</span> as a conference technical paper! Congrats to the team! See you in Vancouver 🍁 </td> </tr> <tr> <th scope="row" style="width: 20%">Feb 06, 2025</th> <td> <a href="https://arxiv.org/html/2503.06122v1" rel="external nofollow noopener" target="_blank">FloraJing🪷</a> was accepted by <a href="https://chi2025.acm.org/" rel="external nofollow noopener" target="_blank"><span style="color: #DA7493;">CHI25</span></a> as a full paper, see you in Yokohama 🌊🌸 Congrats to Wynne! </td> </tr> <tr> <th scope="row" style="width: 20%">Apr 16, 2024</th> <td> Attending IEEE VR24, Orlando, Florida. <img class="emoji" title=":sunflower:" alt=":sunflower:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f33b.png" height="20" width="20"> <img class="emoji" title=":leaves:" alt=":leaves:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f343.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 30, 2024</th> <td> Glad to continue HCI research at MEI Lab, CityUHK as a PhD student 24 Fall! <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"> <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 22, 2024</th> <td> <a class="news-title" href="/news/PetPresenceAccepted/">Project "PetPresence" was accepted by IEEE TVCG, and will be presented in IEEE VR 2024!</a> </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7700"> <a href="https://dl.acm.org/conference/chi" rel="external nofollow noopener" target="_blank">ACM CHI</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/FloraJing-teaser.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="FloraJing-teaser.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2025facilitating" class="col-sm-8"> <div class="title">Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement</div> <div class="author"> <a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a>, <em>Qingqin Liu</em>, Xiaoying Wei, and Mingming Fan<sup>†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="† corresponding author"> </i> </div> <div class="periodical"> <em>In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</em>, Yokohama, Japan., 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706598.3713409" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> </div> <div class="abstract hidden"> <p>The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR’s potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners’ challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#12db76"> <a href="https://www.computer.org/csdl/journal/tg" rel="external nofollow noopener" target="_blank">IEEE TVCG</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/PetVR-teaser.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="PetVR-teaser.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xiong2024petpresence" class="col-sm-8"> <div class="title">Petpresence: Investigating the integration of real-world pet activities in virtual reality</div> <div class="author"> Ningchang Xiong, <em>Qingqin Liu</em>, and <a href="https://zhukening.wixsite.com/aboutme" rel="external nofollow noopener" target="_blank">Kening Zhu<sup>†</sup></a> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="† corresponding author"> </i> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10458353" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/PetPresence.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets’ movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users’ performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/tour-360.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tour-360.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022redirected" class="col-sm-8"> <div class="title">Redirected Walking in 360° Video: Effect of Environment Size on Detection Thresholds for Translation and Rotation Gains</div> <div class="author"> Yanxiang Zhang, <em>Qingqin Liu</em>, and <a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00266" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757447" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-01.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Using real walking to control the playback of the 360° videos is a natural and immersive way to match visual and self-motion perception. Redirected walking can enable users to walk in limited physical tracking space but experience larger scenes. Environment size may affect user perception in 360° videos. We conducted a user study about the detection thresholds (DTs) for translation and rotation gains in 360° video-based virtual environments in three scenes with different widths. Results show that environment size of the scene increases the DTs for both lower and upper translation gains but doesn’t affect the DTs for rotation gains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/touch-360.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="touch-360.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022touch" class="col-sm-8"> <div class="title">Touch the History in Virtuality: Combine Passive Haptic with 360° Videos in History Learning</div> <div class="author"> Yanxiang Zhang, <a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a>, and <em>Qingqin Liu</em> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757459" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>History learning can help learners understand changes and establish identity. 360° videos can display complex history scenes, but limited to the visual and auditory. Passive haptic can provide tactile feedback by matching physical props to virtual counterparts. Utilizing passive haptic in 360° videos can create a diverse and rich experience but face matching problems because of perspective distortion. We propose using high-fidelity models and mapping videos to a cube space to solve this problem. The results of a 28 participants user study show that combining passive haptic with 360° videos enhances users’ presence in historical experience.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/sloped-shoes.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sloped-shoes.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022sloped" class="col-sm-8"> <div class="title">The Sloped Shoes: Influence Human Perception of the Virtual Slope</div> <div class="author"> Yanxiang Zhang, Jialing Wu, and <em>Qingqin Liu</em> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00264" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757641" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-03.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>At present, there is little research on redirected walking in the direction of the slope. In this study, people were allowed to walk uphill or downhill in virtual environments by changing the slope of users’ shoes, while they walked on a flat wooden board in physical environments. We can explore the impact of the shoe slope on users’ perception of walking uphill or downhill in the virtual world. We find that the slope of the shoes affects participants’ perception, increasing their sense of realism when walking uphill and downhill in the virtual world. With increasing or decreasing the shoe slope, participants’ perception of the possibility of walking uphill or downhill will also change and establish corresponding detection thresholds.</p> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%71%69%6E%67%71%69%6E%6C%69%75@%6D%61%69%6C.%75%73%74%63.%65%64%75.%63%6E" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gdTfyxcAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://dblp.org/pid/318/7859.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> <a href="https://neoluxqq.github.io/" title="Neo"> <img src="/assets/img/Neo_icon.jpeg" alt="Neo"> </a> </div> <div class="contact-note">Feel free to email me for anything! </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Qingqin LIU. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>