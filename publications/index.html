<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="G3foir8QYLnJJqtRWe213B0DnbLbQUanZcivMkiIIzI"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> publications | Qingqin Liu | HCI, VR, Haptics </title> <meta name="author" content="Qingqin Liu"> <meta name="description" content="feel free to email me for details"> <meta name="keywords" content="Human-Computer Interaction, VR/AR, Haptics, Creative Experience"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/Neo2.jpeg?c2f6229e6d58e39851748a29e7153b12"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://neoluxqq.github.io/publications/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Qingqin Liu | HCI, VR, Haptics </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">more <span class="sr-only">(current)</span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item active" href="/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/projects/">projects</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">publications</h1> <p class="post-description">feel free to email me for details</p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#902D38"> <a href="https://www.siggraph.org/" rel="external nofollow noopener" target="_blank">SIGGRAPH</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/blossom-preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="blossom-preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2025blossom" class="col-sm-8"> <div class="title">Blossoms Across Time: AI-Assisted Cultural Dialogue Through Diverse Artistic Expressions in VR Intangible Cultural Heritage Experience</div> <div class="author"> <a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a>,¬†<em>Qingqin Liu</em>,¬†Xiaoying Wei,¬†and¬†Mingming Fan<sup>‚Ä†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="‚Ä† corresponding author"> </i> </div> <div class="periodical"> <em>In ACM SIGGRAPH 2025 Immersive Pavilion</em>, Vancouver, BC, Canada, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3721245.3734052" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/Blossoms.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Intangible Cultural Heritage (ICH) serves as a bridge between past, present, and future. For ICH traditions that have experienced historical disruptions, ancient texts and paintings provide invaluable insights. However, current VR systems for ICH often focus on static preservation, while AI applications remain largely limited to archival and documentation tasks. We present Timeless Blossoms, an AI-assisted VR system that enables practitioners to engage in realistic 3D flower arrangement while witnessing their Traditional Chinese Flower Arrangement (TCFA) compositions transform into 2D Xieyi (Chinese expressive) paintings in real time. By enabling participants to engage in a cross-temporal and cross-medium creative process, Timeless Blossoms offers a novel approach to cultural heritage preservation through AI and VR. Our work advances the discourse on AI-assisted cultural creativity by demonstrating how computational techniques can bridge diverse artistic expressions within ICH experiences.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#902D38"> <a href="https://www.siggraph.org/" rel="external nofollow noopener" target="_blank">SIGGRAPH</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/VirCHEW-preview.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="VirCHEW-preview.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="liu2025virchew" class="col-sm-8"> <div class="title">VirCHEW Reality: On-Face Kinesthetic Feedback for Enhancing Food-Intake Experience in Virtual Reality</div> <div class="author"> <em>Qingqin Liu</em>,¬†Ziqi Fang,¬†Jiayi Wu,¬†Shaoyu Cai,¬†Jianhui Yan,¬†Tiande Mo,¬†Shuk Ching CHAN,¬†and¬†<a href="https://zhukening.wixsite.com/aboutme" rel="external nofollow noopener" target="_blank">Kening Zhu<sup>‚Ä†</sup></a> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="‚Ä† corresponding author"> </i> <span class="award-trophy ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content='Top 10 "Audience Choice" at SIGGRAPH 2025 Papers Fast Forward ü•≥' style="cursor:pointer;" title="Award">üèÜ</span> </div> <div class="periodical"> <em>In ACM SIGGRAPH 2025 Conference Papers</em>, Vancouver, BC, Canada, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="award btn btn-sm z-depth-0" role="button">Award</a> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3721238.3730694" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/VirCHEW-0514.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="award hidden d-print-inline"> <p></p> <p>Top 10 ‚ÄúAudience Choice‚Äù at SIGGRAPH 2025 Papers Fast Forward ü•≥</p> </div> <div class="abstract hidden"> <p>While haptic interfaces for virtual reality (VR) has received extensive research attention, on-face haptics in VR remained less explored, especially for virtual food intake. In this paper, we introduce VirCHEW Reality, a face-worn haptic device designed to provide on-face kinesthetic force feedback, to enhance the virtual food-chewing experience in VR. Leveraging a pneumatic actuation system, VirCHEW Reality controlled the process of air inflation and deflation, to simulate the mechanical properties of food textures, such as hardness, cohesiveness, and stickiness. We evaluated the system through three user studies. First, a just-noticeable difference (JND) study examined users‚Äô sensitivity to and the system‚Äôs capability of rendering different levels of on-face pneumatic-based kinesthetic feedback while users performing chewing action. Building upon the user-distinguishable signal ranges found in the first study, we further conducted a matching study to explore the correspondence between the kinesthetic stimuli provided by our device and user-perceived food textures, revealing the capability of simulating food texture properties during chewing (e.g., hardness, cohesiveness, stickiness). Finally, a user study in a VR eating scenario showed that VirCHEW Reality could significantly improve the users‚Äô ratings on the sense of presence, compared to the condition without haptic feedback. Our findings further highlighted possible applications in virtual/remote dining, healthcare, and immersive entertainment.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7700"> <a href="https://dl.acm.org/conference/chi" rel="external nofollow noopener" target="_blank">ACM CHI</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/FloraJing-teaser.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="FloraJing-teaser.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="wang2025facilitating" class="col-sm-8"> <div class="title">Facilitating Daily Practice in Intangible Cultural Heritage through Virtual Reality: A Case Study of Traditional Chinese Flower Arrangement</div> <div class="author"> <a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a>,¬†<em>Qingqin Liu</em>,¬†Xiaoying Wei,¬†and¬†Mingming Fan<sup>‚Ä†</sup> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="‚Ä† corresponding author"> </i> </div> <div class="periodical"> <em>In Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems</em>, Yokohama, Japan, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3706598.3713409" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="/assets/pdf/FloraJing.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>The essence of intangible cultural heritage (ICH) lies in the living knowledge and skills passed down through generations. Daily practice plays a vital role in revitalizing ICH by fostering continuous learning and improvement. However, limited resources and accessibility pose significant challenges to sustaining such practice. Virtual reality (VR) has shown promise in supporting extensive skill training. Unlike technical skill training, ICH daily practice prioritizes cultivating a deeper understanding of cultural meanings and values. This study explores VR‚Äôs potential in facilitating ICH daily practice through a case study of Traditional Chinese Flower Arrangement (TCFA). By investigating TCFA learners‚Äô challenges and expectations, we designed and evaluated FloraJing, a VR system enriched with cultural elements to support sustained TCFA practice. Findings reveal that FloraJing promotes progressive reflection, and continuous enhances technical improvement and cultural understanding. We further propose design implications for VR applications aimed at fostering ICH daily practice in both knowledge and skills.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#12db76"> <a href="https://www.computer.org/csdl/journal/tg" rel="external nofollow noopener" target="_blank">IEEE TVCG</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/PetVR-teaser.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="PetVR-teaser.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="xiong2024petpresence" class="col-sm-8"> <div class="title">Petpresence: Investigating the integration of real-world pet activities in virtual reality</div> <div class="author"> Ningchang Xiong#,¬†Qingqin Liu#,¬†and¬†<a href="https://zhukening.wixsite.com/aboutme" rel="external nofollow noopener" target="_blank">Kening Zhu<sup>‚Ä†</sup></a> <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="# contributed equally, ‚Ä† corresponding author"> </i> </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://ieeexplore.ieee.org/document/10458353" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/PetPresence.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>For VR interaction, the home environment with complicated spatial setup and dynamics may hinder the VR user experience. In particular, pets‚Äô movement may be more unpredictable. In this paper, we investigate the integration of real-world pet activities into immersive VR interaction. Our pilot study showed that the active pet movements, especially dogs, could negatively impact users‚Äô performance and experience in immersive VR. We proposed three different types of pet integration, namely semitransparent real-world portal, non-interactive object in VR, and interactive object in VR. We conducted the user study with 16 pet owners and their pets. The results showed that compared to the baseline condition without any pet-integration technique, the approach of integrating the pet as interactive objects in VR yielded significantly higher participant ratings in perceived realism, joy, multisensory engagement, and connection with their pets in VR.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/tour-360.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tour-360.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022redirected" class="col-sm-8"> <div class="title">Redirected Walking in 360¬∞ Video: Effect of Environment Size on Detection Thresholds for Translation and Rotation Gains</div> <div class="author"> Yanxiang Zhang,¬†<em>Qingqin Liu</em>,¬†and¬†<a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00266" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757447" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-01.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>Using real walking to control the playback of the 360¬∞ videos is a natural and immersive way to match visual and self-motion perception. Redirected walking can enable users to walk in limited physical tracking space but experience larger scenes. Environment size may affect user perception in 360¬∞ videos. We conducted a user study about the detection thresholds (DTs) for translation and rotation gains in 360¬∞ video-based virtual environments in three scenes with different widths. Results show that environment size of the scene increases the DTs for both lower and upper translation gains but doesn‚Äôt affect the DTs for rotation gains.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/touch-360.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="touch-360.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022touch" class="col-sm-8"> <div class="title">Touch the History in Virtuality: Combine Passive Haptic with 360¬∞ Videos in History Learning</div> <div class="author"> Yanxiang Zhang,¬†<a href="http://home.ustc.edu.cn/~wynnewang" rel="external nofollow noopener" target="_blank">Yingna Wang</a>,¬†and¬†<em>Qingqin Liu</em> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00263" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757459" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-02.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>History learning can help learners understand changes and establish identity. 360¬∞ videos can display complex history scenes, but limited to the visual and auditory. Passive haptic can provide tactile feedback by matching physical props to virtual counterparts. Utilizing passive haptic in 360¬∞ videos can create a diverse and rich experience but face matching problems because of perspective distortion. We propose using high-fidelity models and mapping videos to a cube space to solve this problem. The results of a 28 participants user study show that combining passive haptic with 360¬∞ videos enhances users‚Äô presence in historical experience.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00529b"> <a href="https://www.ieeevr.org/" rel="external nofollow noopener" target="_blank">IEEE VR</a> </abbr> <figure> <picture> <img src="/assets/img/publication_preview/sloped-shoes.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="sloped-shoes.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zhang2022sloped" class="col-sm-8"> <div class="title">The Sloped Shoes: Influence Human Perception of the Virtual Slope</div> <div class="author"> Yanxiang Zhang,¬†Jialing Wu,¬†and¬†<em>Qingqin Liu</em> </div> <div class="periodical"> <em>In 2022 IEEE Conference on Virtual Reality and 3D User Interfaces Abstracts and Workshops (VRW)</em>, Mar 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/VRW55335.2022.00264" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="https://ieeexplore.ieee.org/document/9757641" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/pub-03.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="abstract hidden"> <p>At present, there is little research on redirected walking in the direction of the slope. In this study, people were allowed to walk uphill or downhill in virtual environments by changing the slope of users‚Äô shoes, while they walked on a flat wooden board in physical environments. We can explore the impact of the shoe slope on users‚Äô perception of walking uphill or downhill in the virtual world. We find that the slope of the shoes affects participants‚Äô perception, increasing their sense of realism when walking uphill and downhill in the virtual world. With increasing or decreasing the shoe slope, participants‚Äô perception of the possibility of walking uphill or downhill will also change and establish corresponding detection thresholds.</p> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> ¬© Copyright 2025 Qingqin Liu. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>